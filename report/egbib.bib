[LR] (https://epubs.siam.org/doi/abs/10.1137/080738970)
[LRTV] (https://ieeexplore.ieee.org/abstract/document/7113897/)
LRL0: a designed based-line, which employs L0 gradient minimization

@ARTICLE{fast,
  author={Xian, Chuhua and Zhang, Dongjiu and Dai, Chengkai and Wang, Charlie C. L.},
  journal={IEEE Transactions on Automation Science and Engineering}, 
  title={Fast Generation of High-Fidelity RGB-D Images by Deep Learning With Adaptive Convolution}, 
  year={2021},
  volume={18},
  number={3},
  pages={1328-1340},
  doi={10.1109/TASE.2020.3002069}
 }

@INPROCEEDINGS{inpainting,
  author={Patil, P. M. and Deokate, B. H.},
  booktitle={2015 International Conference on Information Processing (ICIP)}, 
  title={Image mapping and object removal in image inpainting using wavelet transform}, 
  year={2015},
  volume={},
  number={},
  pages={114-118},
  doi={10.1109/INFOP.2015.7489361}}

@INPROCEEDINGS{singledepth,
  author={Zhang, Yinda and Funkhouser, Thomas},
  booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 
  title={Deep Depth Completion of a Single RGB-D Image}, 
  year={2018},
  volume={},
  number={},
  pages={175-185},
  doi={10.1109/CVPR.2018.00026}}

@INPROCEEDINGS{LR,
  author={Fan, Runze and Lu, Yang and Wu, Shiqian},
  booktitle={2019 14th IEEE Conference on Industrial Electronics and Applications (ICIEA)}, 
  title={Image inpainting based on low-rank ALM algorithm}, 
  year={2019},
  volume={},
  number={},
  pages={2373-2378},
  doi={10.1109/ICIEA.2019.8931109}}


@ARTICLE{LRTV,
  author={Shi, Feng and Cheng, Jian and Wang, Li and Yap, Pew-Thian and Shen, Dinggang},
  journal={IEEE Transactions on Medical Imaging}, 
  title={LRTV: MR Image Super-Resolution With Low-Rank and Total Variation Regularizations}, 
  year={2015},
  volume={34},
  number={12},
  pages={2459-2466},
  doi={10.1109/TMI.2015.2437894}}

@INPROCEEDINGS{psnr,
  author={Joshi, Kamaldeep and Yadav, Rajkumar and Allwadhi, Sachin},
  booktitle={2016 International Conference on Computational Techniques in Information and Communication Technologies (ICCTICT)}, 
  title={PSNR and MSE based investigation of LSB}, 
  year={2016},
  volume={},
  number={},
  pages={280-285},
  doi={10.1109/ICCTICT.2016.7514593}}



@INPROCEEDINGS{LRl0,
  author={Wang, Minghua and Wang, Qiang and Chanussot, Jocelyn},
  booktitle={2019 10th Workshop on Hyperspectral Imaging and Signal Processing: Evolution in Remote Sensing (WHISPERS)}, 
  title={L<inf>0</inf> Gradient Regularized Low-Rank Tensor Model for Hyperspectral Image Denoising}, 
  year={2019},
  volume={},
  number={},
  pages={1-6},
  doi={10.1109/WHISPERS.2019.8920965}}




@article{lrl0phi,
  title={Depth image inpainting: Improving low rank matrix completion with low gradient regularization},
  author={Xue, Hongyang and Zhang, Shengming and Cai, Deng},
  journal={IEEE Transactions on Image Processing},
  volume={26},
  number={9},
  pages={4311--4320},
  year={2017},
  publisher={IEEE}
}






----- old ------

@article{ASL,
  title={Asymmetric Loss For Multi-Label Classification},
  author={Ben-Baruch, Emanuel and Ridnik, Tal and Zamir, Nadav and Noy, Asaf and Friedman, Itamar and Protter, Matan and Zelnik-Manor, Lihi},
  journal={arXiv preprint arXiv:2009.14119},
  year={2020}
}


@inproceedings{MLGCN,
  title={Multi-label image recognition with graph convolutional networks},
  author={Chen, Zhao-Min and Wei, Xiu-Shen and Wang, Peng and Guo, Yanwen},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={5177--5186},
  year={2019}
}

@article{2017adam2sgd,
  title={Improving generalization performance by switching from adam to sgd},
  author={Keskar, Nitish Shirish and Socher, Richard},
  journal={arXiv preprint arXiv:1712.07628},
  year={2017}
}

@article{metapseudo,
  title={Meta pseudo labels},
  author={Pham, Hieu and Xie, Qizhe and Dai, Zihang and Le, Quoc V},
  journal={arXiv preprint arXiv:2003.10580},
  year={2020}
}

@article{image2set,
  title={Elucidating image-to-set prediction: An analysis of models, losses and datasets},
  author={Pineda, Luis and Salvador, Amaia and Drozdzal, Michal and Romero, Adriana},
  journal={arXiv preprint arXiv:1904.05709},
  year={2019}
}

@inproceedings{largescaleobjectdetection,
  title={Large-Scale Object Detection in the Wild from Imbalanced Multi-Labels},
  author={Peng, Junran and Bu, Xingyuan and Sun, Ming and Zhang, Zhaoxiang and Tan, Tieniu and Yan, Junjie},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9709--9718},
  year={2020}
}


@inproceedings{2018mobilenetv2,
  title={Mobilenetv2: Inverted residuals and linear bottlenecks},
  author={Sandler, Mark and Howard, Andrew and Zhu, Menglong and Zhmoginov, Andrey and Chen, Liang-Chieh},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4510--4520},
  year={2018}
}

@inproceedings{2018shufflenet,
  title={Shufflenet v2: Practical guidelines for efficient cnn architecture design},
  author={Ma, Ningning and Zhang, Xiangyu and Zheng, Hai-Tao and Sun, Jian},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={116--131},
  year={2018}
}

@inproceedings{2019efficientnet,
  title={Efficientnet: Rethinking model scaling for convolutional neural networks},
  author={Tan, Mingxing and Le, Quoc},
  booktitle={International Conference on Machine Learning},
  pages={6105--6114},
  year={2019},
  organization={PMLR}
}

@article{2014vgg,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}

@inproceedings{2016resenet,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{2019multilabelreduction,
  title={Multilabel reductions: what is my loss optimising?},
  author={Menon, Aditya K and Rawat, Ankit Singh and Reddi, Sashank and Kumar, Sanjiv},
  year={2019}
}


@inproceedings{2015unet,
  title={U-net: Convolutional networks for biomedical image segmentation},
  author={Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  booktitle={International Conference on Medical image computing and computer-assisted intervention},
  pages={234--241},
  year={2015},
  organization={Springer}
}

@article{2018autoaugment,
  title={Autoaugment: Learning augmentation policies from data},
  author={Cubuk, Ekin D and Zoph, Barret and Mane, Dandelion and Vasudevan, Vijay and Le, Quoc V},
  journal={arXiv preprint arXiv:1805.09501},
  year={2018}
}

@inproceedings{2017cyclical,
  title={Cyclical learning rates for training neural networks},
  author={Smith, Leslie N},
  booktitle={2017 IEEE winter conference on applications of computer vision (WACV)},
  pages={464--472},
  year={2017},
  organization={IEEE}
}


@inproceedings{2020gc_ranger,
  title={Gradient centralization: A new optimization technique for deep neural networks},
  author={Yong, Hongwei and Huang, Jianqiang and Hua, Xiansheng and Zhang, Lei},
  booktitle={European Conference on Computer Vision},
  pages={635--652},
  year={2020},
  organization={Springer}
}

@article{2018doubleA2,
  title={$ A\^{} 2$-Nets: Double Attention Networks},
  author={Chen, Yunpeng and Kalantidis, Yannis and Li, Jianshu and Yan, Shuicheng and Feng, Jiashi},
  journal={arXiv preprint arXiv:1810.11579},
  year={2018}
}


@inproceedings{2017focalloss,
  title={Focal loss for dense object detection},
  author={Lin, Tsung-Yi and Goyal, Priya and Girshick, Ross and He, Kaiming and Doll{\'a}r, Piotr},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2980--2988},
  year={2017}
}

@article{2020biobert,
  title={BioBERT: a pre-trained biomedical language representation model for biomedical text mining},
  author={Lee, Jinhyuk and Yoon, Wonjin and Kim, Sungdong and Kim, Donghyeon and Kim, Sunkyu and So, Chan Ho and Kang, Jaewoo},
  journal={Bioinformatics},
  volume={36},
  number={4},
  pages={1234--1240},
  year={2020},
  publisher={Oxford University Press}
}

@inproceedings{carion2020end,
  title={End-to-end object detection with transformers},
  author={Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
  booktitle={European Conference on Computer Vision},
  pages={213--229},
  year={2020},
  organization={Springer}
}

@inproceedings{10.5555/3295222.3295349,
author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, undefinedukasz and Polosukhin, Illia},
title = {Attention is All You Need},
year = {2017},
isbn = {9781510860964},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.0 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature.},
booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
pages = {6000–6010},
numpages = {11},
location = {Long Beach, California, USA},
series = {NIPS'17}
}